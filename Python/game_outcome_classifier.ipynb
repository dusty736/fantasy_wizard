{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9430811-845b-404d-8f75-4aa4ccd0911f",
   "metadata": {},
   "source": [
    "# Game Outcome Model\n",
    "\n",
    "This notebook will test a number of classifier and logistic regression models to predict game outcome.\n",
    "\n",
    "Models Include:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3074065-e6f7-41ff-96a3-ce52274fae21",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c748b6-6a22-40de-9f28-b8768aa38149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import IPython\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import interact, interactive\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from utils import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import random\n",
    "\n",
    "import yellowbrick\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3afdda0-8411-49b8-a58b-f84f12cd35a8",
   "metadata": {},
   "source": [
    "## Set Folder Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d182a8f-55ba-43f8-a38b-11ab810a987e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Navigate two folders up\n",
    "#os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "os.chdir(\"/Users/dusty/Desktop/projects/sports_analytics.nosync/fantasy_wizard/\")\n",
    "\n",
    "# Print the new working directory\n",
    "print(\"Working In:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25f448-076e-4809-af2a-8475e1093774",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be5f9a-cf0d-4357-a309-1f55ab578626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load rb data\n",
    "game_data = pd.read_csv(os.path.join(os.getcwd(), \"data\", \"processed\", \"games\", \"modeling_game_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5442a9-d142-426c-90b0-4d09b267fcae",
   "metadata": {},
   "source": [
    "## Investigate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311430cf-d544-4e5a-b317-c2055c55fc22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "game_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeaf8cd-99a1-4796-ad72-200ff28c7239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "game_data.sort_values(by='game_id').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068e815-0aa1-44a6-a6a2-5ea7f1e8ce00",
   "metadata": {},
   "source": [
    "### Numeric Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2afb8-76c8-45d9-9aea-985d5eb2f2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = []\n",
    "\n",
    "varset_1 = [26] + list(range(1, 20))\n",
    "#sns.pairplot(game_data.iloc[:,varset_1], hue='result')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5f47b-4a6b-4551-aec7-823eff19499c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['season', 'apy_cap_pct', 'years_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b900a-22bb-4878-8a7e-4622109dc311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varset_2 = list(set([26] + list(range(21, 30))))\n",
    "#sns.pairplot(game_data.iloc[:,varset_2], hue='result')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946f4d8-502d-4d56-97c8-1f199acf7cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['favored', 'rolling_win_pct', 'rolling_off_ppg', 'rolling_off_pypg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9463b49-00ae-420a-bc2c-38ecc06488b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varset_3 = [26] + list(range(31, 40))\n",
    "#sns.pairplot(game_data.iloc[:,varset_3], hue='result')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4fd45-c32b-4478-a990-c301bec78d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['roll_off_typg', 'rolling_off_ptdpg', 'rolling_off_rtdpg', 'rolling_off_ttdpg', 'rolling_def_rypg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3bded-1f93-49cf-a9ca-a98d2eac85cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varset_4 = [26] + list(range(41, 50))\n",
    "#sns.pairplot(game_data.iloc[:,varset_4], hue='result')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a3434-3f35-4c09-97a8-6224dc5ba7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['rolling_def_ttdpg', 'rolling_avg_air_yards_differential','rolling_avg_attempts', 'rolling_avg_pass_yards', 'rolling_avg_pass_touchdowns', 'rolling_avg_interceptions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed767f10-c6ce-404f-9e3b-b50e93722a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varset_5 = [26] + list(range(51, 60))\n",
    "#sns.pairplot(game_data.iloc[:,varset_5], hue='result')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256b2bb-b8f2-4b27-bcf0-51a1f29a66d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['prev_season_win_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f220ca-aa95-470a-af88-d052b276dbf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varset_6 = [26] + list(range(61, 70))\n",
    "#sns.pairplot(game_data.iloc[:,varset_6], hue='result')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104737b1-aa46-460d-a280-55b43ab7570c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['prev_season_off_plays_per_game', 'prev_season_off_run_pct', 'prev_season_off_pass_pct', 'prev_season_off_pypg', 'prev_season_off_rypg',\n",
    "                               'prev_season_off_typg', 'prev_season_off_ptdpg', 'prev_season_off_rtdpg', 'prev_season_off_ttdpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09106e6c-8fb4-44d4-ab47-d3fb25428bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varset_7 = [26] + list(range(71, 86))\n",
    "#sns.pairplot(game_data.iloc[:,varset_7], hue='result')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e510ae-8c91-470d-89a6-d4889da5879e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_vars = numeric_vars + ['prev_season_off_spg', 'prev_season_off_ipg', 'prev_season_def_ppg', 'prev_season_def_plays_per_game',\n",
    "                               'prev_season_def_pypg', 'prev_season_def_typg', 'prev_season_def_spg', 'prev_season_def_ipg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79871f3b-0e19-4af2-a56d-7b371685b30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Numeric Variables that show variation by game outcome: \", numeric_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a22e2-eb8a-4d97-9c9d-9df9d83480e2",
   "metadata": {},
   "source": [
    "### Categorical Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c38f474-0e0b-4adc-b6f9-30f9426a22a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "game_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20c090-ad54-44fd-9c47-7f2f64210e30",
   "metadata": {},
   "source": [
    "## Split into Train, Test, Validation Sets\n",
    "- 80-20 split\n",
    "- Validation year will be 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabce5c-a09f-4a3b-9fa2-c67a35022a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Target Columns\n",
    "target_columns = ['result']\n",
    "\n",
    "# Separate validation data\n",
    "validation_season = game_data[game_data['season'] == 2023]\n",
    "validation_season_x = validation_season.drop(columns=target_columns)\n",
    "validation_season_y = validation_season.result\n",
    "\n",
    "# Remove validation season\n",
    "modeling_seasons = game_data[game_data['season'] != 2023]\n",
    "\n",
    "# Separate Modeling Data\n",
    "modeling_data_x = modeling_seasons.drop(columns=target_columns)\n",
    "modeling_data_y = modeling_seasons.result\n",
    "\n",
    "# Split into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    modeling_data_x, modeling_data_y, train_size=0.8, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "modeling_data_span = sorted(set(modeling_data_x.season))\n",
    "validation_data_span = sorted(set(validation_season_x.season))\n",
    "\n",
    "print(\"Modeling Seasons: \", modeling_data_span)\n",
    "print(\"Validation Seasons: \", validation_data_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3974ed-74a8-434a-98c5-d506f112e4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Training Data Dimensions: {X_train.shape}\")\n",
    "print(f\"Test Data Dimensions: {X_test.shape}\")\n",
    "\n",
    "assert(X_train.shape[0] == y_train.shape[0])\n",
    "assert(X_test.shape[0] == y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398884ab-326e-4e3d-80f0-5f902ca93e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf1545-3b4c-40e9-83b7-522c52dd81b7",
   "metadata": {},
   "source": [
    "## Define Columns for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66349f-2bda-4fa6-a48e-b055f3b8670f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modeling_columns = ['apy_cap_pct', 'years_left', 'spread_line',\n",
    "                   'rolling_win_pct', 'rolling_off_ppg', 'rolling_off_pypg',\n",
    "                   'rolling_off_rypg', 'rolling_off_typg', 'rolling_off_ptdpg',\n",
    "                   'rolling_off_rtdpg', 'rolling_off_ttdpg', 'rolling_def_ppg',\n",
    "                   'rolling_def_pypg', 'rolling_def_rypg', 'rolling_def_typg',\n",
    "                   'rolling_def_ptdpg', 'rolling_def_rtdpg', 'rolling_def_ttdpg',\n",
    "                   'rolling_avg_time_to_throw', 'rolling_avg_completed_air_yards',\n",
    "                   'rolling_avg_intended_air_yards', 'rolling_avg_air_yards_differential',\n",
    "                   'rolling_avg_attempts', 'rolling_avg_pass_yards',\n",
    "                   'rolling_avg_pass_touchdowns', 'rolling_avg_interceptions',\n",
    "                   'rolling_avg_passer_rating', 'rolling_avg_completions',\n",
    "                   'rolling_avg_completion_percentage',\n",
    "                   'rolling_avg_expected_completion_percentage',\n",
    "                   'rolling_avg_completion_percentage_above_expectation',\n",
    "                   'rolling_avg_avg_air_distance', 'rolling_avg_max_air_distance',\n",
    "                   'rolling_n_on_report', 'rolling_n_on_practice_report',\n",
    "                   'prev_season_win_pct', 'prev_season_off_ppg',\n",
    "                   'prev_season_off_plays_per_game', 'prev_season_off_run_pct',\n",
    "                   'prev_season_off_pass_pct', 'prev_season_off_pypg',\n",
    "                   'prev_season_off_rypg', 'prev_season_off_typg', 'prev_season_off_ptdpg',\n",
    "                   'prev_season_off_rtdpg', 'prev_season_off_ttdpg',\n",
    "                   'prev_season_off_fdpg', 'prev_season_off_spg', 'prev_season_off_ipg',\n",
    "                   'prev_season_def_ppg', 'prev_season_def_plays_per_game',\n",
    "                   'prev_season_def_run_pct', 'prev_season_def_pass_pct',\n",
    "                   'prev_season_def_pypg', 'prev_season_def_rypg', 'prev_season_def_typg',\n",
    "                   'prev_season_def_ptdpg', 'prev_season_def_rtdpg',\n",
    "                   'prev_season_def_ttdpg', 'prev_season_def_fdpg', 'prev_season_def_spg',\n",
    "                   'prev_season_def_ipg']\n",
    "\n",
    "drop_columns = ['game_id', 'team', 'points_scored', 'points_allowed', 'score']\n",
    "\n",
    "# Get cat columns\n",
    "cat_columns = ['season', 'week', 'game_type', 'home_away',\n",
    "               'stadium_id', 'weekday', 'game_window', 'qb', 'coach', 'opposing_qb',\n",
    "               'opposing_coach', 'home_rest', 'away_rest',\n",
    "               'div_game', 'roof', 'temp_conditions', 'wind_conditions', 'favored']\n",
    "\n",
    "# Get numeric columns\n",
    "non_numeric_columns = drop_columns + cat_columns\n",
    "numeric_columns = X_train.drop(columns=non_numeric_columns).columns\n",
    "\n",
    "assert(len(numeric_columns) + len(drop_columns) + len(cat_columns) == len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb07f4-cabc-4bdc-855b-46763a90d3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "\n",
    "# Impute missing data\n",
    "#imputer = SimpleImputer(strategy=\"median\")\n",
    "#PCA_data = imputer.fit_transform(modeling_data[numeric_columns])\n",
    "PCA_data = modeling_data_x[numeric_columns].dropna()\n",
    "\n",
    "# Create scaling object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit scaling object\n",
    "scaler.fit(modeling_data_x[numeric_columns].dropna())\n",
    "\n",
    "# Create transformed data\n",
    "scaled_modeling_data = pd.DataFrame(scaler.transform(modeling_data_x[numeric_columns].dropna()), columns=numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6da698-6eb7-4f9e-abed-e51a6d9392c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating and fitting the model\n",
    "pca = PCA(n_components=14, random_state=42).fit(PCA_data)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(range(1, 15), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xticks(range(1, 15))\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"explained variance\")\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef85134-9f8d-490b-88e6-bb7137c2ff52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13187d7c-5090-4f4f-983f-a921cee2e446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ba442-6084-4920-9168-c4596c62bc6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary\n",
    "\n",
    "*Eight* PCA components explain ~96% of the explained variance in the data, so I will use 8 PCs in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f3269-3191-4b1b-94fb-cf805aae72e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_pc = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33422ab-fa01-4b73-adfc-74587c72cf34",
   "metadata": {},
   "source": [
    "### Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff0a18-d3a8-4452-8e96-08b73cde0f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), \n",
    "                                    StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_columns),\n",
    "    (numeric_transformer, numeric_columns),\n",
    "    (categorical_transformer, cat_columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920938d-8f34-49e0-bdf4-0e538f88fc20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Default Pipelines\n",
    "pipe_logistic = make_pipeline(preprocessor, \n",
    "                              PCA(n_components=n_pc), \n",
    "                              LogisticRegression())\n",
    "pipe_decision_tree = make_pipeline(preprocessor, \n",
    "                                   PCA(n_components=n_pc), \n",
    "                                   DecisionTreeClassifier())\n",
    "pipe_random_forest = make_pipeline(preprocessor, \n",
    "                                   PCA(n_components=n_pc), \n",
    "                                   RandomForestClassifier())\n",
    "pipe_naive_bayes = make_pipeline(preprocessor, \n",
    "                                 PCA(n_components=n_pc), \n",
    "                                 BernoulliNB())\n",
    "pipe_xgboost = make_pipeline(preprocessor, \n",
    "                             PCA(n_components=n_pc), \n",
    "                             xgb.XGBClassifier())\n",
    "\n",
    "# Define Parameter Grids\n",
    "logistic_param_grid = {\n",
    "    'regressor__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'regressor__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "    'regressor__solver': ['liblinear', 'saga']        # Algorithm for optimization\n",
    "}\n",
    "\n",
    "# Define Parameter Grids for Decision Tree\n",
    "decision_tree_param_grid = {\n",
    "    'classifier__max_depth': [None, 5, 10, 15],         # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],        # Minimum samples required to split a node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],          # Minimum samples required at each leaf node\n",
    "    'classifier__max_features': ['sqrt', 'log2'] # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Define Parameter Grids for Random Forest\n",
    "random_forest_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],     # Number of trees in the forest\n",
    "    'classifier__max_depth': [None, 5, 10, 15],       # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],      # Minimum samples required to split a node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],        # Minimum samples required at each leaf node\n",
    "    'classifier__max_features': ['sqrt', 'log2'] # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "naive_bayes_param_grid = {\n",
    "    'classifier__alpha': [0.1, 0.5, 1.0],           # Smoothing parameter\n",
    "    'classifier__binarize': [0.0, 0.1, 0.5],        # Threshold for binarizing features\n",
    "    'classifier__fit_prior': [True, False],         # Whether to learn class prior probabilities\n",
    "    'classifier__class_prior': [None, [0.3, 0.7]]   # Prior probabilities of the classes\n",
    "}\n",
    "\n",
    "# Define Parameter Grids for XGBoost\n",
    "xgboost_param_grid = {\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],             # Boosting learning rate\n",
    "    'classifier__max_depth': [3, 5, 7],                        # Maximum depth of a tree\n",
    "    'classifier__n_estimators': [100, 200, 300],               # Number of boosting rounds\n",
    "    'classifier__gamma': [0, 0.1, 0.2],                        # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    'classifier__subsample': [0.8, 0.9, 1.0],                  # Subsample ratio of the training instances\n",
    "    'classifier__colsample_bytree': [0.8, 0.9, 1.0]            # Subsample ratio of columns when constructing each tree\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e22367-e362-4f1b-88d8-42b07283ea1b",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aee0fe-697e-4401-b698-6d5432d2eb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tmp pipeline\n",
    "opt_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('pca', pipe_logistic['pca']),\n",
    "                         ('regressor', pipe_logistic['logisticregression'])])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_logistic = GridSearchCV(opt_pipeline, logistic_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid_search_logistic.best_params_)\n",
    "print(\"Best score: \", grid_search_logistic.best_score_)\n",
    "\n",
    "# Define Winning Model\n",
    "#params_logistic = grid_search_logistic.best_params_\n",
    "#params_logistic = {'regressor__C': 0.1, \n",
    "#                   'regressor__penalty': 'l1', \n",
    "#                   'regressor__solver': 'liblinear'}\n",
    "#print(params_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c698cd3-e999-45a0-89cd-243cc576d8f8",
   "metadata": {},
   "source": [
    "## Model 2: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4a0dc-c8f5-4195-87bd-8410085f1b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tmp pipeline\n",
    "opt_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('pca', pipe_decision_tree['pca']),\n",
    "                         ('classifier', pipe_decision_tree['decisiontreeclassifier'])])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_dt = GridSearchCV(opt_pipeline, decision_tree_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid_search_dt.best_params_)\n",
    "print(\"Best score: \", grid_search_dt.best_score_)\n",
    "\n",
    "# Define Winning Model\n",
    "params_dt = grid_search_dt.best_params_\n",
    "#params_dt = {'classifier__max_depth': 5, \n",
    "#             'classifier__max_features': 'sqrt', \n",
    "#             'classifier__min_samples_leaf': 2, \n",
    "#             'classifier__min_samples_split': 2}\n",
    "#print(params_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700a5b9-ba5c-47b4-a17a-e00417d6485a",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0f785-bab4-40da-9290-073e45e8a4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tmp pipeline\n",
    "opt_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('pca', pipe_random_forest['pca']),\n",
    "                         ('classifier', pipe_random_forest['randomforestclassifier'])])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_rf = GridSearchCV(opt_pipeline, random_forest_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid_search_rf.best_params_)\n",
    "print(\"Best score: \", grid_search_rf.best_score_)\n",
    "\n",
    "# Define Winning Model\n",
    "params_rf = grid_search_rf.best_params_\n",
    "#params_rf = {'classifier__max_depth': 5, \n",
    "#             'classifier__max_features': 'log2', \n",
    "#             'classifier__min_samples_leaf': 4, \n",
    "#             'classifier__min_samples_split': 5, \n",
    "#             'classifier__n_estimators': 100}\n",
    "#print(params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be31150-9044-4bb7-8d1d-62aff6029533",
   "metadata": {},
   "source": [
    "## Model 4: Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5006cb-14d4-4e33-a034-681f23043341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tmp pipeline\n",
    "opt_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('pca', pipe_naive_bayes['pca']),\n",
    "                         ('classifier', pipe_naive_bayes['bernoullinb'])])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_nb = GridSearchCV(opt_pipeline, naive_bayes_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid_search_nb.best_params_)\n",
    "print(\"Best score: \", grid_search_nb.best_score_)\n",
    "\n",
    "# Define Winning Model\n",
    "params_nb = grid_search_nb.best_params_\n",
    "#params_nb = {'classifier__alpha': 0.1, \n",
    "#             'classifier__binarize': 0.0, \n",
    "#             'classifier__class_prior': None, \n",
    "#             'classifier__fit_prior': False}\n",
    "#print(params_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f6928-d025-44ca-8924-2854712b5612",
   "metadata": {},
   "source": [
    "## Model 5: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69736e75-c369-40cd-bf52-68e01fc0ce80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tmp pipeline\n",
    "opt_pipeline = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('pca', pipe_xgboost['pca']),\n",
    "                         ('classifier', pipe_xgboost['xgbclassifier'])])\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_xgb = GridSearchCV(opt_pipeline, xgboost_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid_search_xgb.best_params_)\n",
    "print(\"Best score: \", grid_search_xgb.best_score_)\n",
    "\n",
    "# Define Winning Model\n",
    "params_xgb = grid_search_xgb.best_params_\n",
    "#params_xgb = {'classifier__colsample_bytree': 0.9, \n",
    "#              'classifier__gamma': 0.1, \n",
    "#              'classifier__learning_rate': 0.01, \n",
    "#              'classifier__max_depth': 3, \n",
    "#              'classifier__n_estimators': 100, \n",
    "#              'classifier__subsample': 0.9}\n",
    "#print(params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0793031-1596-490d-b4a7-416b29a826b6",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0872a5f-cdab-41de-b574-9cf1a1df3305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71d3aa-695a-4a4a-8a7d-24fa2a9371be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82e8c0-a65a-4f37-8253-d4bba4500d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Logist Regression\n",
    "LR_pipe = make_pipeline(preprocessor,\n",
    "                       PCA(n_components=n_pc),\n",
    "                       LogisticRegression(C = params_logistic['regressor__C'],\n",
    "                                          penalty = params_logistic['regressor__penalty'],\n",
    "                                          solver = params_logistic['regressor__solver']))\n",
    "\n",
    "# Define Decision Tree\n",
    "DT_pipe = make_pipeline(preprocessor, \n",
    "                       PCA(n_components=n_pc),\n",
    "                       DecisionTreeClassifier(max_depth = params_dt['classifier__max_depth'],\n",
    "                                                 max_features = params_dt['classifier__max_features'],\n",
    "                                                 min_samples_leaf = params_dt['classifier__min_samples_leaf'],\n",
    "                                                 min_samples_split = params_dt['classifier__min_samples_split']))\n",
    "\n",
    "# Define Random Forest\n",
    "RF_pipe = make_pipeline(preprocessor, \n",
    "                        PCA(n_components=n_pc),\n",
    "                        RandomForestClassifier(max_depth = params_rf['classifier__max_depth'],\n",
    "                                               max_features = params_rf['classifier__max_features'],\n",
    "                                               min_samples_leaf = params_rf['classifier__min_samples_leaf'],\n",
    "                                               min_samples_split = params_rf['classifier__min_samples_split'],\n",
    "                                               n_estimators = params_rf['classifier__n_estimators']))\n",
    "\n",
    "# Define Naive Bayes - Bernoulli\n",
    "NB_pipe = make_pipeline(preprocessor, \n",
    "                         PCA(n_components=n_pc),\n",
    "                         BernoulliNB(alpha = params_nb['classifier__alpha'],\n",
    "                                     binarize = params_nb['classifier__binarize'],\n",
    "                                     class_prior = params_nb['classifier__class_prior'],\n",
    "                                     fit_prior = params_nb['classifier__fit_prior']))\n",
    "\n",
    "# Define XGBoost Classifier\n",
    "XGB_pipe = make_pipeline(preprocessor, \n",
    "                         PCA(n_components=n_pc),\n",
    "                         xgb.XGBClassifier\n",
    "                         (colsample_bytree = params_xgb['classifier__colsample_bytree'],\n",
    "                             gamma = params_xgb['classifier__gamma'],\n",
    "                             learning_rate = params_xgb['classifier__learning_rate'],\n",
    "                             max_depth = params_xgb['classifier__max_depth'],\n",
    "                             n_estimators = params_xgb['classifier__n_estimators'],\n",
    "                             subsample = params_xgb['classifier__subsample']))\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\" : LR_pipe,\n",
    "    \"Decision Tree\" : DT_pipe,\n",
    "    \"Random Forest\" : RF_pipe,\n",
    "    \"Naive Bayes Bernoulli\" : NB_pipe,\n",
    "    \"XGBoost\" : XGB_pipe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1059b-a451-4379-918c-eb69a660f7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for (name, model) in models.items():\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccfa2bd-2d23-4b05-8053-de675097cd6f",
   "metadata": {},
   "source": [
    "## Winning Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1ad3e-48ac-400a-ac9d-5e6c9612ca8a",
   "metadata": {},
   "source": [
    "### Fit Winning Middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75939ed6-845b-442b-8b60-8f5f1079fb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_fit = LR_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a0671-0f76-42af-8a19-d19e1b763e8c",
   "metadata": {},
   "source": [
    "### Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579ed4f-cd97-4543-adef-3a9838c2e9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_predictions = LR_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ab62a-c42d-445f-8b38-982a82d76eba",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b9bc9-4a1f-48c6-ac03-b359c3a8b477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates various evaluation metrics for a binary classification problem.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): True labels\n",
    "    - y_pred (array-like): Predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of the model\n",
    "    - f1 (float): F1 score of the model\n",
    "    - auc (float): AUC-ROC of the model\n",
    "    - precision (float): precision of the model\n",
    "    - recall (float): recall of the model\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    precision = report['1']['precision']\n",
    "    recall = report['1']['recall']\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    \n",
    "    return (accuracy, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b74bc-d5cb-49fb-bdce-08dd7e113a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_performance = evaluate_model(y_test, LR_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea0777-bf0c-4451-bdd3-3735e4808446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map encoded values to name values\n",
    "# labels\n",
    "labels = ['loss', 'win']\n",
    "\n",
    "# Create vectorized function for labeling encoded data (thanks chatGPT)\n",
    "int2label = np.vectorize(lambda x: labels[x])\n",
    "\n",
    "# Apply actual labels\n",
    "LR_predictions_labeled = int2label(LR_predictions)\n",
    "y_test_labeled = int2label(y_test.apply(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea229f-fc3c-4f09-8795-83781a49b16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test_labeled, \n",
    "                            LR_predictions_labeled, \n",
    "                            normalize='true')\n",
    "\n",
    "sns.heatmap(conf_mat, \n",
    "            annot=True,\n",
    "            xticklabels=labels, \n",
    "            yticklabels=labels, )\n",
    "plt.title('Logistic Regression Prediction Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58409ed9-25e0-4e26-8844-9606ea564e8a",
   "metadata": {},
   "source": [
    "## Predict Validation Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899107a7-29f0-458b-970c-7a31e9f8a372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_2023 = LR_fit.predict(validation_season_x)\n",
    "probabilites_2023 = LR_fit.predict_proba(validation_season_x)\n",
    "win_probabilities_2023 = probabilites_2023[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9723400-87e8-4a21-94b2-a3870b20c729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_season['predicted_result'] = predictions_2023\n",
    "validation_season['prediction_confidence'] = win_probabilities_2023\n",
    "output = validation_season.loc[:,['game_id', 'season', 'week' , 'team', 'home_away', 'spread_line', \n",
    "                              'points_scored', 'points_allowed', 'favored', 'result', \n",
    "                              'predicted_result', 'prediction_confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c9974-df5e-4f6c-af1a-57a71c89ac07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.sort_values(by=['season', 'week', 'team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9e5a7-fbc5-4a30-864b-1709c4b812a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
